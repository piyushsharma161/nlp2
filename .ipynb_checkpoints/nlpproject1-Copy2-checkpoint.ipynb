{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('smsspamcollection/SMSSpamCollection', sep ='\\t', names=['labels', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                            message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                            message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels  = {'ham':0, 'spam':1}\n",
    "messages['labels'] = [labels[item] for item in messages['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                            message\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "token1 = RegexpTokenizer(r'[a-zA-Z]+' r'\\w{1,}')\n",
    "def text_process(mess):\n",
    "    # Remove punc\n",
    "    # Remove stop words\n",
    "    \n",
    "    nopunc = re.sub(\",\", '', ''.join(mess))\n",
    "    nopunc = [char for char in nopunc.split() if char.lower() not in stopwords.words('english')]\n",
    "    nopunc = [char for char in nopunc if char not in string.punctuation] \n",
    "    return ' '.join(token1.tokenize(' '.join(nopunc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['message'] = messages['message'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "nbmodel = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_params = {'vect__ngram_range':[(1,1),(1,2)], 'classify__alpha':[0.01,0.1,1,10,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline([('vect', vectorizer), ('tf', tfidf),('classify', nbmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..._tf=False, use_idf=True)), ('classify', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'classify__alpha': [0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit='recall_score',\n",
       "       return_train_score=False,\n",
       "       scoring={'precision_score': make_scorer(precision_score), 'recall_score': make_scorer(recall_score), 'accuracy_score': make_scorer(accuracy_score)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "grid = GridSearchCV(nb_pipeline, nb_params, cv=5, scoring=scorers, return_train_score=False, refit='recall_score')\n",
    "grid.fit(messages['message'], messages['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210042703128939"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classify__alpha': 0.01, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(grid.cv_results_)[['rank_test_precision_score','mean_test_precision_score','rank_test_recall_score', 'mean_test_recall_score','rank_test_accuracy_score','mean_test_accuracy_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>mean_test_accuracy_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972573</td>\n",
       "      <td>0.896898</td>\n",
       "      <td>0.982771</td>\n",
       "      <td>{'classify__alpha': 0.01, 'vect__ngram_range':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966899</td>\n",
       "      <td>0.921004</td>\n",
       "      <td>0.985104</td>\n",
       "      <td>{'classify__alpha': 0.01, 'vect__ngram_range':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979434</td>\n",
       "      <td>0.891539</td>\n",
       "      <td>0.982950</td>\n",
       "      <td>{'classify__alpha': 0.1, 'vect__ngram_range': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984295</td>\n",
       "      <td>0.898240</td>\n",
       "      <td>0.984386</td>\n",
       "      <td>{'classify__alpha': 0.1, 'vect__ngram_range': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998246</td>\n",
       "      <td>0.749603</td>\n",
       "      <td>0.966260</td>\n",
       "      <td>{'classify__alpha': 1, 'vect__ngram_range': (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.958004</td>\n",
       "      <td>{'classify__alpha': 1, 'vect__ngram_range': (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.868449</td>\n",
       "      <td>{'classify__alpha': 10, 'vect__ngram_range': (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865937</td>\n",
       "      <td>{'classify__alpha': 10, 'vect__ngram_range': (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865937</td>\n",
       "      <td>{'classify__alpha': 100, 'vect__ngram_range': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865937</td>\n",
       "      <td>{'classify__alpha': 100, 'vect__ngram_range': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_precision_score  mean_test_recall_score  \\\n",
       "0                   0.972573                0.896898   \n",
       "1                   0.966899                0.921004   \n",
       "2                   0.979434                0.891539   \n",
       "3                   0.984295                0.898240   \n",
       "4                   0.998246                0.749603   \n",
       "5                   1.000000                0.686747   \n",
       "6                   1.000000                0.018754   \n",
       "7                   0.000000                0.000000   \n",
       "8                   0.000000                0.000000   \n",
       "9                   0.000000                0.000000   \n",
       "\n",
       "   mean_test_accuracy_score                                             params  \n",
       "0                  0.982771  {'classify__alpha': 0.01, 'vect__ngram_range':...  \n",
       "1                  0.985104  {'classify__alpha': 0.01, 'vect__ngram_range':...  \n",
       "2                  0.982950  {'classify__alpha': 0.1, 'vect__ngram_range': ...  \n",
       "3                  0.984386  {'classify__alpha': 0.1, 'vect__ngram_range': ...  \n",
       "4                  0.966260  {'classify__alpha': 1, 'vect__ngram_range': (1...  \n",
       "5                  0.958004  {'classify__alpha': 1, 'vect__ngram_range': (1...  \n",
       "6                  0.868449  {'classify__alpha': 10, 'vect__ngram_range': (...  \n",
       "7                  0.865937  {'classify__alpha': 10, 'vect__ngram_range': (...  \n",
       "8                  0.865937  {'classify__alpha': 100, 'vect__ngram_range': ...  \n",
       "9                  0.865937  {'classify__alpha': 100, 'vect__ngram_range': ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['mean_test_precision_score','mean_test_recall_score','mean_test_accuracy_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'classify__alpha': 0.01, 'vect__ngram_range': (1, 1)},\n",
       " {'classify__alpha': 0.01, 'vect__ngram_range': (1, 2)},\n",
       " {'classify__alpha': 0.1, 'vect__ngram_range': (1, 1)},\n",
       " {'classify__alpha': 0.1, 'vect__ngram_range': (1, 2)},\n",
       " {'classify__alpha': 1, 'vect__ngram_range': (1, 1)},\n",
       " {'classify__alpha': 1, 'vect__ngram_range': (1, 2)},\n",
       " {'classify__alpha': 10, 'vect__ngram_range': (1, 1)},\n",
       " {'classify__alpha': 10, 'vect__ngram_range': (1, 2)},\n",
       " {'classify__alpha': 100, 'vect__ngram_range': (1, 1)},\n",
       " {'classify__alpha': 100, 'vect__ngram_range': (1, 2)}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.16774645, 0.31149945, 0.11636128, 0.2992053 , 0.13080578,\n",
       "        0.35657535, 0.13272901, 0.31232347, 0.13143659, 0.30129819]),\n",
       " 'std_fit_time': array([0.06288862, 0.01365031, 0.00428341, 0.00466977, 0.01932867,\n",
       "        0.04282254, 0.0288405 , 0.02141032, 0.01832953, 0.00773289]),\n",
       " 'mean_score_time': array([0.11158905, 0.16950288, 0.07887845, 0.14178877, 0.08575883,\n",
       "        0.17143607, 0.08565078, 0.14625278, 0.08445215, 0.14316196]),\n",
       " 'std_score_time': array([0.03912365, 0.03905329, 0.00135481, 0.00362036, 0.01073895,\n",
       "        0.02672678, 0.0077588 , 0.00502931, 0.00237141, 0.00284932]),\n",
       " 'param_classify__alpha': masked_array(data=[0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 1), (1, 2), (1, 1), (1, 2), (1, 1),\n",
       "                    (1, 2), (1, 1), (1, 2)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classify__alpha': 0.01, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 0.01, 'vect__ngram_range': (1, 2)},\n",
       "  {'classify__alpha': 0.1, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 0.1, 'vect__ngram_range': (1, 2)},\n",
       "  {'classify__alpha': 1, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 1, 'vect__ngram_range': (1, 2)},\n",
       "  {'classify__alpha': 10, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 10, 'vect__ngram_range': (1, 2)},\n",
       "  {'classify__alpha': 100, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 100, 'vect__ngram_range': (1, 2)}],\n",
       " 'split0_test_precision_score': array([0.97241379, 0.94701987, 0.99295775, 0.97222222, 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split1_test_precision_score': array([0.97761194, 0.97826087, 0.97744361, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split2_test_precision_score': array([0.97761194, 0.98529412, 0.98484848, 0.9924812 , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split3_test_precision_score': array([0.97777778, 0.9787234 , 0.98507463, 0.9924812 , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split4_test_precision_score': array([0.95744681, 0.94520548, 0.95683453, 0.96428571, 0.99122807,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'mean_test_precision_score': array([0.97257333, 0.96689922, 0.97943387, 0.98429472, 0.99824624,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'std_test_precision_score': array([0.00783085, 0.01716403, 0.01231761, 0.01361483, 0.0035083 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_precision_score': array([6, 7, 5, 4, 3, 1, 1, 8, 8, 8], dtype=int32),\n",
       " 'split0_test_recall_score': array([0.94      , 0.95333333, 0.94      , 0.93333333, 0.80666667,\n",
       "        0.69333333, 0.00666667, 0.        , 0.        , 0.        ]),\n",
       " 'split1_test_recall_score': array([0.87333333, 0.9       , 0.86666667, 0.88      , 0.74666667,\n",
       "        0.68      , 0.02      , 0.        , 0.        , 0.        ]),\n",
       " 'split2_test_recall_score': array([0.87919463, 0.89932886, 0.87248322, 0.88590604, 0.69127517,\n",
       "        0.66442953, 0.02684564, 0.        , 0.        , 0.        ]),\n",
       " 'split3_test_recall_score': array([0.88590604, 0.9261745 , 0.88590604, 0.88590604, 0.74496644,\n",
       "        0.69127517, 0.01342282, 0.        , 0.        , 0.        ]),\n",
       " 'split4_test_recall_score': array([0.90604027, 0.9261745 , 0.89261745, 0.90604027, 0.75838926,\n",
       "        0.70469799, 0.02684564, 0.        , 0.        , 0.        ]),\n",
       " 'mean_test_recall_score': array([0.89689836, 0.92100427, 0.89153891, 0.89824016, 0.74960256,\n",
       "        0.68674717, 0.01875421, 0.        , 0.        , 0.        ]),\n",
       " 'std_test_recall_score': array([0.02421571, 0.02005116, 0.0259406 , 0.01964713, 0.03678646,\n",
       "        0.01363422, 0.00783644, 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_recall_score': array([3, 1, 4, 2, 5, 6, 7, 8, 8, 8], dtype=int32),\n",
       " 'split0_test_accuracy_score': array([0.98834081, 0.98654709, 0.99103139, 0.98744395, 0.97399103,\n",
       "        0.95874439, 0.86636771, 0.86547085, 0.86547085, 0.86547085]),\n",
       " 'split1_test_accuracy_score': array([0.98026906, 0.9838565 , 0.9793722 , 0.9838565 , 0.96591928,\n",
       "        0.95695067, 0.86816143, 0.86547085, 0.86547085, 0.86547085]),\n",
       " 'split2_test_accuracy_score': array([0.98114901, 0.98473968, 0.98114901, 0.98384201, 0.95870736,\n",
       "        0.9551167 , 0.86983842, 0.86624776, 0.86624776, 0.86624776]),\n",
       " 'split3_test_accuracy_score': array([0.98204668, 0.98743268, 0.98294434, 0.98384201, 0.96588869,\n",
       "        0.95870736, 0.86804309, 0.86624776, 0.86624776, 0.86624776]),\n",
       " 'split4_test_accuracy_score': array([0.98204668, 0.98294434, 0.98025135, 0.98294434, 0.96678636,\n",
       "        0.96050269, 0.86983842, 0.86624776, 0.86624776, 0.86624776]),\n",
       " 'mean_test_accuracy_score': array([0.982771  , 0.98510409, 0.98295047, 0.98438622, 0.96625987,\n",
       "        0.95800431, 0.86844939, 0.86593683, 0.86593683, 0.86593683]),\n",
       " 'std_test_accuracy_score': array([0.00286291, 0.00166473, 0.00421127, 0.00156881, 0.00484466,\n",
       "        0.00182909, 0.00129932, 0.00038064, 0.00038064, 0.00038064]),\n",
       " 'rank_test_accuracy_score': array([4, 1, 3, 2, 5, 6, 7, 8, 8, 8], dtype=int32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
