{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param is:  {'classify__alpha': 0.01, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Read the CSV input file\n",
    "messages = pd.read_csv('smsspamcollection/SMSSpamCollection', sep ='\\t', names=['labels', 'message'])\n",
    "\n",
    "#convert categorical target variable to numeric\n",
    "labels  = {'ham':0, 'spam':1}  \n",
    "\n",
    "messages['labels'] = [labels[item] for item in messages['labels']]\n",
    "\n",
    "# test data pre-processing\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "token1 = RegexpTokenizer(r'[a-zA-Z]+' r'\\w{1,}') # Removing all, keeping only alphanumeric and string of length >= 2\n",
    "\n",
    "def text_process(mess):\n",
    "    # Remove punc\n",
    "    # Remove stop words\n",
    "    \n",
    "    nopunc = re.sub(\",\", '', ''.join(mess))\n",
    "    nopunc = [char for char in nopunc.split() if char.lower() not in stopwords.words('english')]\n",
    "    nopunc = [char for char in nopunc if char not in string.punctuation] \n",
    "    return ' '.join(token1.tokenize(' '.join(nopunc)))\n",
    "\n",
    "\n",
    "\n",
    "messages['message'] = messages['message'].apply(text_process)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "nbmodel = MultinomialNB()\n",
    "\n",
    "# define param field for the pipeline\n",
    "nb_params = {'vect__ngram_range':[(1,1),(1,2)], 'classify__alpha':[0.01,0.1,1,10,100]}\n",
    "\n",
    "# define pipeline for the model\n",
    "nb_pipeline = Pipeline([('vect', vectorizer), ('tf', tfidf),('classify', nbmodel)])\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "\n",
    "# define model validation crireria, we will use recall score to rank the model performance\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#instanciate grid search cv with fold of 5 \n",
    "grid = GridSearchCV(nb_pipeline, nb_params, cv=5, scoring=scorers, return_train_score=False, refit='recall_score')\n",
    "\n",
    "grid.fit(messages['message'], messages['labels'])\n",
    "\n",
    "# print best parameter for the model\n",
    "print('best param is: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>mean_test_accuracy_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972573</td>\n",
       "      <td>0.896898</td>\n",
       "      <td>0.982771</td>\n",
       "      <td>{'classify__alpha': 0.01, 'vect__ngram_range':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966899</td>\n",
       "      <td>0.921004</td>\n",
       "      <td>0.985104</td>\n",
       "      <td>{'classify__alpha': 0.01, 'vect__ngram_range':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979434</td>\n",
       "      <td>0.891539</td>\n",
       "      <td>0.982950</td>\n",
       "      <td>{'classify__alpha': 0.1, 'vect__ngram_range': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984295</td>\n",
       "      <td>0.898240</td>\n",
       "      <td>0.984386</td>\n",
       "      <td>{'classify__alpha': 0.1, 'vect__ngram_range': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998246</td>\n",
       "      <td>0.749603</td>\n",
       "      <td>0.966260</td>\n",
       "      <td>{'classify__alpha': 1, 'vect__ngram_range': (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.958004</td>\n",
       "      <td>{'classify__alpha': 1, 'vect__ngram_range': (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.868449</td>\n",
       "      <td>{'classify__alpha': 10, 'vect__ngram_range': (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865937</td>\n",
       "      <td>{'classify__alpha': 10, 'vect__ngram_range': (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865937</td>\n",
       "      <td>{'classify__alpha': 100, 'vect__ngram_range': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865937</td>\n",
       "      <td>{'classify__alpha': 100, 'vect__ngram_range': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_precision_score  mean_test_recall_score  \\\n",
       "0                   0.972573                0.896898   \n",
       "1                   0.966899                0.921004   \n",
       "2                   0.979434                0.891539   \n",
       "3                   0.984295                0.898240   \n",
       "4                   0.998246                0.749603   \n",
       "5                   1.000000                0.686747   \n",
       "6                   1.000000                0.018754   \n",
       "7                   0.000000                0.000000   \n",
       "8                   0.000000                0.000000   \n",
       "9                   0.000000                0.000000   \n",
       "\n",
       "   mean_test_accuracy_score                                             params  \n",
       "0                  0.982771  {'classify__alpha': 0.01, 'vect__ngram_range':...  \n",
       "1                  0.985104  {'classify__alpha': 0.01, 'vect__ngram_range':...  \n",
       "2                  0.982950  {'classify__alpha': 0.1, 'vect__ngram_range': ...  \n",
       "3                  0.984386  {'classify__alpha': 0.1, 'vect__ngram_range': ...  \n",
       "4                  0.966260  {'classify__alpha': 1, 'vect__ngram_range': (1...  \n",
       "5                  0.958004  {'classify__alpha': 1, 'vect__ngram_range': (1...  \n",
       "6                  0.868449  {'classify__alpha': 10, 'vect__ngram_range': (...  \n",
       "7                  0.865937  {'classify__alpha': 10, 'vect__ngram_range': (...  \n",
       "8                  0.865937  {'classify__alpha': 100, 'vect__ngram_range': ...  \n",
       "9                  0.865937  {'classify__alpha': 100, 'vect__ngram_range': ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['mean_test_precision_score','mean_test_recall_score','mean_test_accuracy_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.11860294, 0.2816813 , 0.11509743, 0.32600341, 0.12545919,\n",
       "        0.28933582, 0.13083119, 0.33189764, 0.11768727, 0.30449648]),\n",
       " 'std_fit_time': array([0.00456864, 0.00523117, 0.00513386, 0.03743566, 0.00722947,\n",
       "        0.00738127, 0.01879092, 0.05950554, 0.00462623, 0.02876556]),\n",
       " 'mean_score_time': array([0.08009405, 0.13556809, 0.07904463, 0.20110893, 0.08282952,\n",
       "        0.14595118, 0.09577198, 0.14066978, 0.07826161, 0.14839211]),\n",
       " 'std_score_time': array([0.00504522, 0.00431416, 0.00363729, 0.07554815, 0.00593123,\n",
       "        0.00966799, 0.02175819, 0.00324467, 0.00283855, 0.01115585]),\n",
       " 'param_classify__alpha': masked_array(data=[0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 1), (1, 2), (1, 1), (1, 2), (1, 1),\n",
       "                    (1, 2), (1, 1), (1, 2)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classify__alpha': 0.01, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 0.01, 'vect__ngram_range': (1, 2)},\n",
       "  {'classify__alpha': 0.1, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 0.1, 'vect__ngram_range': (1, 2)},\n",
       "  {'classify__alpha': 1, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 1, 'vect__ngram_range': (1, 2)},\n",
       "  {'classify__alpha': 10, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 10, 'vect__ngram_range': (1, 2)},\n",
       "  {'classify__alpha': 100, 'vect__ngram_range': (1, 1)},\n",
       "  {'classify__alpha': 100, 'vect__ngram_range': (1, 2)}],\n",
       " 'split0_test_precision_score': array([0.97241379, 0.94701987, 0.99295775, 0.97222222, 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split1_test_precision_score': array([0.97761194, 0.97826087, 0.97744361, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split2_test_precision_score': array([0.97761194, 0.98529412, 0.98484848, 0.9924812 , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split3_test_precision_score': array([0.97777778, 0.9787234 , 0.98507463, 0.9924812 , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split4_test_precision_score': array([0.95744681, 0.94520548, 0.95683453, 0.96428571, 0.99122807,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'mean_test_precision_score': array([0.97257333, 0.96689922, 0.97943387, 0.98429472, 0.99824624,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'std_test_precision_score': array([0.00783085, 0.01716403, 0.01231761, 0.01361483, 0.0035083 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_precision_score': array([6, 7, 5, 4, 3, 1, 1, 8, 8, 8], dtype=int32),\n",
       " 'split0_test_recall_score': array([0.94      , 0.95333333, 0.94      , 0.93333333, 0.80666667,\n",
       "        0.69333333, 0.00666667, 0.        , 0.        , 0.        ]),\n",
       " 'split1_test_recall_score': array([0.87333333, 0.9       , 0.86666667, 0.88      , 0.74666667,\n",
       "        0.68      , 0.02      , 0.        , 0.        , 0.        ]),\n",
       " 'split2_test_recall_score': array([0.87919463, 0.89932886, 0.87248322, 0.88590604, 0.69127517,\n",
       "        0.66442953, 0.02684564, 0.        , 0.        , 0.        ]),\n",
       " 'split3_test_recall_score': array([0.88590604, 0.9261745 , 0.88590604, 0.88590604, 0.74496644,\n",
       "        0.69127517, 0.01342282, 0.        , 0.        , 0.        ]),\n",
       " 'split4_test_recall_score': array([0.90604027, 0.9261745 , 0.89261745, 0.90604027, 0.75838926,\n",
       "        0.70469799, 0.02684564, 0.        , 0.        , 0.        ]),\n",
       " 'mean_test_recall_score': array([0.89689836, 0.92100427, 0.89153891, 0.89824016, 0.74960256,\n",
       "        0.68674717, 0.01875421, 0.        , 0.        , 0.        ]),\n",
       " 'std_test_recall_score': array([0.02421571, 0.02005116, 0.0259406 , 0.01964713, 0.03678646,\n",
       "        0.01363422, 0.00783644, 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_recall_score': array([3, 1, 4, 2, 5, 6, 7, 8, 8, 8], dtype=int32),\n",
       " 'split0_test_accuracy_score': array([0.98834081, 0.98654709, 0.99103139, 0.98744395, 0.97399103,\n",
       "        0.95874439, 0.86636771, 0.86547085, 0.86547085, 0.86547085]),\n",
       " 'split1_test_accuracy_score': array([0.98026906, 0.9838565 , 0.9793722 , 0.9838565 , 0.96591928,\n",
       "        0.95695067, 0.86816143, 0.86547085, 0.86547085, 0.86547085]),\n",
       " 'split2_test_accuracy_score': array([0.98114901, 0.98473968, 0.98114901, 0.98384201, 0.95870736,\n",
       "        0.9551167 , 0.86983842, 0.86624776, 0.86624776, 0.86624776]),\n",
       " 'split3_test_accuracy_score': array([0.98204668, 0.98743268, 0.98294434, 0.98384201, 0.96588869,\n",
       "        0.95870736, 0.86804309, 0.86624776, 0.86624776, 0.86624776]),\n",
       " 'split4_test_accuracy_score': array([0.98204668, 0.98294434, 0.98025135, 0.98294434, 0.96678636,\n",
       "        0.96050269, 0.86983842, 0.86624776, 0.86624776, 0.86624776]),\n",
       " 'mean_test_accuracy_score': array([0.982771  , 0.98510409, 0.98295047, 0.98438622, 0.96625987,\n",
       "        0.95800431, 0.86844939, 0.86593683, 0.86593683, 0.86593683]),\n",
       " 'std_test_accuracy_score': array([0.00286291, 0.00166473, 0.00421127, 0.00156881, 0.00484466,\n",
       "        0.00182909, 0.00129932, 0.00038064, 0.00038064, 0.00038064]),\n",
       " 'rank_test_accuracy_score': array([4, 1, 3, 2, 5, 6, 7, 8, 8, 8], dtype=int32)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
